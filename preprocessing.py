def word_tokeniser(sent, language="chinese"):
    return [token for token in sent]